#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTubeéŸ³å£°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼
"""

import numpy as np
import pyaudio
import librosa
import sounddevice as sd
from scipy import signal
from scipy.fft import fft
import threading
import time
import queue
from typing import List, Tuple, Optional, Dict
import cv2
from PIL import Image, ImageDraw, ImageFont
import os

class AudioVisualizer:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼"""
    
    def __init__(self, sample_rate=44100, chunk_size=1024, num_bars=32):
        """åˆæœŸåŒ–"""
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.num_bars = num_bars
        self.audio_queue = queue.Queue()
        self.is_recording = False
        self.audio_thread = None
        
        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¨­å®š
        self.channels = 1
        self.format = pyaudio.paFloat32
        
        # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
        self.bar_heights = np.zeros(num_bars)
        self.frequency_bands = self._create_frequency_bands()
        
        # è‰²è¨­å®š
        self.colors = self._create_color_palette()
        
        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ 
        self.audio = pyaudio.PyAudio()
        self.stream = None
        
    def _create_frequency_bands(self) -> List[Tuple[int, int]]:
        """å‘¨æ³¢æ•°å¸¯åŸŸã‚’ä½œæˆ"""
        bands = []
        # ä½å‘¨æ³¢æ•°ã‹ã‚‰é«˜å‘¨æ³¢æ•°ã¾ã§å¯¾æ•°çš„ã«åˆ†å‰²
        low_freq = 20
        high_freq = 20000
        
        for i in range(self.num_bars):
            start_freq = int(low_freq * (high_freq / low_freq) ** (i / self.num_bars))
            end_freq = int(low_freq * (high_freq / low_freq) ** ((i + 1) / self.num_bars))
            bands.append((start_freq, end_freq))
        
        return bands
    
    def _create_color_palette(self) -> List[Tuple[int, int, int]]:
        """ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆã‚’ä½œæˆ"""
        colors = []
        # ä½å‘¨æ³¢æ•°ï¼ˆé’ï¼‰ã‹ã‚‰é«˜å‘¨æ³¢æ•°ï¼ˆèµ¤ï¼‰ã¸ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        for i in range(self.num_bars):
            ratio = i / (self.num_bars - 1)
            r = int(255 * ratio)
            g = int(100 + 155 * (1 - ratio))
            b = int(255 * (1 - ratio))
            colors.append((r, g, b))
        return colors
    
    def start_recording(self):
        """éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹"""
        if self.is_recording:
            return
        
        try:
            self.stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                stream_callback=self._audio_callback
            )
            
            self.is_recording = True
            self.audio_thread = threading.Thread(target=self._audio_processing_thread)
            self.audio_thread.daemon = True
            self.audio_thread.start()
            
            print("ğŸ¤ éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"âŒ éŸ³å£°éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop_recording(self):
        """éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢"""
        self.is_recording = False
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        
        if self.audio_thread:
            self.audio_thread.join(timeout=1)
        
        print("ğŸ›‘ éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if self.is_recording:
            self.audio_queue.put(in_data)
        return (None, pyaudio.paContinue)
    
    def _audio_processing_thread(self):
        """éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        while self.is_recording:
            try:
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get_nowait()
                    self._process_audio_chunk(audio_data)
                else:
                    time.sleep(0.01)
            except Exception as e:
                print(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(0.1)
    
    def _process_audio_chunk(self, audio_data):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†"""
        try:
            # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã«å¤‰æ›
            audio_array = np.frombuffer(audio_data, dtype=np.float32)
            
            # FFTã§å‘¨æ³¢æ•°è§£æ
            fft_data = fft(audio_array)
            magnitude = np.abs(fft_data[:len(fft_data)//2])
            
            # å„å‘¨æ³¢æ•°å¸¯åŸŸã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
            for i, (start_freq, end_freq) in enumerate(self.frequency_bands):
                start_bin = int(start_freq * self.chunk_size / self.sample_rate)
                end_bin = int(end_freq * self.chunk_size / self.sample_rate)
                
                if start_bin < len(magnitude) and end_bin < len(magnitude):
                    band_energy = np.mean(magnitude[start_bin:end_bin])
                    
                    # ãƒãƒ¼ã®é«˜ã•ã‚’æ›´æ–°ï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä»˜ãï¼‰
                    target_height = min(1.0, band_energy / 1000)  # æ­£è¦åŒ–
                    self.bar_heights[i] = 0.8 * self.bar_heights[i] + 0.2 * target_height
                    
        except Exception as e:
            print(f"éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_visualization_data(self) -> Tuple[np.ndarray, List[Tuple[int, int, int]]]:
        """ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        return self.bar_heights.copy(), self.colors.copy()
    
    def create_visualization_image(self, width=240, height=240) -> Image.Image:
        """ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã‚’ä½œæˆ"""
        try:
            # ç”»åƒã‚’ä½œæˆ
            image = Image.new('RGB', (width, height), (0, 0, 0))
            draw = ImageDraw.Draw(image)
            
            # ãƒãƒ¼ã®å¹…ã¨é–“éš”ã‚’è¨ˆç®—
            bar_width = width // (self.num_bars + 1)
            bar_spacing = (width - bar_width * self.num_bars) // (self.num_bars + 1)
            
            # å„ãƒãƒ¼ã‚’æç”»
            for i in range(self.num_bars):
                x = bar_spacing + i * (bar_width + bar_spacing)
                bar_height = int(self.bar_heights[i] * height * 0.8)
                y = height - bar_height
                
                # ãƒãƒ¼ã®è‰²ã‚’å–å¾—
                color = self.colors[i]
                
                # ãƒãƒ¼ã‚’æç”»
                draw.rectangle([x, y, x + bar_width, height], fill=color)
                
                # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœï¼ˆä¸Šéƒ¨ã‚’æ˜ã‚‹ãï¼‰
                for j in range(bar_height):
                    alpha = int(255 * (j / bar_height))
                    bright_color = tuple(min(255, c + alpha // 3) for c in color)
                    draw.line([x, y + j, x + bar_width, y + j], fill=bright_color)
            
            # ä¸­å¤®ã«éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ 
            overall_level = np.mean(self.bar_heights)
            if overall_level > 0.1:  # éŸ³å£°ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
                # å††å½¢ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
                center_x, center_y = width // 2, height // 2
                radius = int(20 + overall_level * 30)
                draw.ellipse([center_x - radius, center_y - radius, 
                            center_x + radius, center_y + radius], 
                           fill=(255, 255, 255), outline=(100, 100, 100))
            
            return image
            
        except Exception as e:
            print(f"ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®ç”»åƒã‚’è¿”ã™
            return Image.new('RGB', (width, height), (0, 0, 0))
    
    def get_audio_levels(self) -> Dict[str, float]:
        """éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        try:
            # ä½å‘¨æ³¢æ•°ã€ä¸­å‘¨æ³¢æ•°ã€é«˜å‘¨æ³¢æ•°ã®ãƒ¬ãƒ™ãƒ«
            low_freq = np.mean(self.bar_heights[:self.num_bars//3])
            mid_freq = np.mean(self.bar_heights[self.num_bars//3:2*self.num_bars//3])
            high_freq = np.mean(self.bar_heights[2*self.num_bars//3:])
            
            # å…¨ä½“ã®ãƒ¬ãƒ™ãƒ«
            overall_level = np.mean(self.bar_heights)
            
            # ãƒ”ãƒ¼ã‚¯æ¤œå‡º
            peak_level = np.max(self.bar_heights)
            
            return {
                'overall': overall_level,
                'low_freq': low_freq,
                'mid_freq': mid_freq,
                'high_freq': high_freq,
                'peak': peak_level,
                'bars': self.bar_heights.tolist()
            }
            
        except Exception as e:
            print(f"éŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.stop_recording()
        if self.audio:
            self.audio.terminate()

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    print("ğŸµ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆ")
    print("=" * 40)
    
    visualizer = AudioVisualizer()
    
    try:
        print("éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™...")
        print("ä½•ã‹éŸ³ã‚’å‡ºã—ã¦ãã ã•ã„ï¼ˆCtrl+Cã§åœæ­¢ï¼‰")
        
        visualizer.start_recording()
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
        while True:
            levels = visualizer.get_audio_levels()
            if levels:
                # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ãƒãƒ¼ã‚’è¡¨ç¤º
                bars = "".join(["â–ˆ" if h > 0.1 else "â–‘" for h in levels['bars'][:20]])
                print(f"\réŸ³å£°ãƒ¬ãƒ™ãƒ«: {bars} | å…¨ä½“: {levels['overall']:.3f}", end='')
            
            time.sleep(0.1)
            
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ãƒ†ã‚¹ãƒˆã‚’åœæ­¢ã—ã¾ã—ãŸ")
    finally:
        visualizer.cleanup()
